{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from assignment2.dataset import load_svhn, random_split_train_val\n",
    "from assignment2.gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from assignment2.layers import FullyConnectedLayer, ReLULayer\n",
    "from assignment2.model import TwoLayerNet\n",
    "from assignment2.trainer import Trainer, Dataset \n",
    "from assignment2.optim import SGD, MomentumSGD\n",
    "from assignment2.metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "run batch version of gradient check\n  analytic_grad\n [[ 1.61599406  0.          2.76252524]\n [-0.         -0.5060347  -0.94302519]] \n\n  numeric_grad\n [[ 1.61599406  0.          2.76252524]\n [ 0.         -0.5060347  -0.94302519]] \n\nGradient check passed!\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "run batch version of gradient check\n  analytic_grad\n [[ 4.18948095e-04  1.76337767e-03 -3.49979411e-04]\n [ 7.82747412e-05 -6.12293143e-04 -1.09946675e-03]] \n\n  numeric_grad\n [[ 4.18948095e-04  1.76337767e-03 -3.49979411e-04]\n [ 7.82747412e-05 -6.12293143e-04 -1.09946675e-03]] \n\nGradient check passed!\n\nrun batch version of gradient check\n  analytic_grad\n [[-1.67429365  2.15318718 -0.15893916 -0.56958173]\n [ 3.34858731 -4.30637437  0.31787831  1.13916345]\n [-0.36258122  5.45842018 -3.37773459 -0.89339967]] \n\n  numeric_grad\n [[-1.67429365  2.15318718 -0.15893916 -0.56958173]\n [ 3.34858731 -4.30637437  0.31787831  1.13916345]\n [-0.36258122  5.45842018 -3.37773459 -0.89339967]] \n\nGradient check passed!\n\nrun batch version of gradient check\n  analytic_grad\n [[-0.632844   -0.39002832  1.75340995  0.51081366]] \n\n  numeric_grad\n [[-0.632844   -0.39002832  1.75340995  0.51081366]] \n\nGradient check passed!\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Checking gradient for fc1_W\nrun batch version of gradient check\n",
      "  analytic_grad\n [[ 1.05393580e-05  0.00000000e+00 -2.23528083e-05]\n [ 1.25578983e-05  0.00000000e+00 -4.99938161e-06]\n [ 3.57140937e-05  0.00000000e+00  4.39014438e-05]\n ...\n [-9.80687160e-05  0.00000000e+00 -8.39833186e-05]\n [-8.76305797e-05  0.00000000e+00 -5.28532904e-05]\n [-6.98006962e-05  0.00000000e+00 -2.94876473e-06]] \n\n  numeric_grad\n [[ 1.05393694e-05  0.00000000e+00 -2.23528085e-05]\n [ 1.25578881e-05  0.00000000e+00 -4.99937869e-06]\n [ 3.57140983e-05  0.00000000e+00  4.39014158e-05]\n ...\n [-9.80687087e-05  0.00000000e+00 -8.39833092e-05]\n [-8.76305917e-05  0.00000000e+00 -5.28532773e-05]\n [-6.98006986e-05  0.00000000e+00 -2.94875235e-06]] \n\nGradient check passed!\n\nChecking gradient for fc1_B\nrun batch version of gradient check\n  analytic_grad\n [[0.00065346 0.         0.0006072 ]] \n\n  numeric_grad\n [[0.00065346 0.         0.0006072 ]] \n\nGradient check passed!\n\nChecking gradient for fc2_W\nrun batch version of gradient check\n  analytic_grad\n [[ 0.00037503  0.00037535  0.00037567  0.0003749   0.0003757   0.00037455\n   0.00037548  0.00037493  0.00037505 -0.00337666]\n [ 0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.        ]\n [ 0.00050123  0.00050165  0.00050209  0.00050104  0.00050212  0.00050057\n   0.00050182  0.00050108  0.00050126 -0.00451284]] \n\n  numeric_grad\n [[ 0.00037503  0.00037535  0.00037567  0.0003749   0.00037571  0.00037455\n   0.00037548  0.00037493  0.00037505 -0.00337666]\n [ 0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.        ]\n [ 0.00050123  0.00050165  0.00050209  0.00050104  0.00050212  0.00050057\n   0.00050182  0.00050108  0.00050126 -0.00451284]] \n\nGradient check passed!\n\nChecking gradient for fc2_B\nrun batch version of gradient check\n  analytic_grad\n [[ 0.09993815  0.10002254  0.10010892  0.09990119  0.10011637  0.09980764\n   0.1000566   0.09990923  0.09994333 -0.89980397]] \n\n  numeric_grad\n [[ 0.09993815  0.10002254  0.10010892  0.09990119  0.10011637  0.09980764\n   0.1000566   0.09990923  0.09994333 -0.89980397]] \n\nGradient check passed!\n\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Checking gradient for fc1_W\nrun batch version of gradient check\n",
      "  analytic_grad\n [[-0.01976325 -0.00117834 -0.02135352]\n [ 0.01538378  0.0081576   0.01097304]\n [ 0.02261739 -0.00670261  0.02142476]\n ...\n [-0.00958147  0.00678107 -0.00191968]\n [ 0.03099914 -0.00714554  0.00908816]\n [ 0.02173933  0.0131764   0.01097147]] \n\n  numeric_grad\n [[-0.01976325 -0.00117834 -0.02135352]\n [ 0.01538378  0.0081576   0.01097304]\n [ 0.02261739 -0.00670261  0.02142476]\n ...\n [-0.00958147  0.00678107 -0.00191968]\n [ 0.03099914 -0.00714554  0.00908816]\n [ 0.02173933  0.0131764   0.01097147]] \n\nGradient check passed!\n\nChecking gradient for fc1_B\nrun batch version of gradient check\n  analytic_grad\n [[-0.01013572  0.0029346   0.00803137]] \n\n  numeric_grad\n [[-0.01013572  0.0029346   0.00803137]] \n\nGradient check passed!\n\nChecking gradient for fc2_W\nrun batch version of gradient check\n  analytic_grad\n [[ 0.00339013  0.02963675 -0.00331576  0.00066842  0.05166266  0.01660512\n  -0.01936271  0.00995913  0.01586149 -0.01602389]\n [-0.00517349 -0.02297789  0.00672213 -0.03158611 -0.01491909 -0.02681439\n   0.0074182  -0.00592797  0.00879223 -0.04433188]\n [-0.01543066  0.01599222 -0.02280474  0.02064731 -0.00284956 -0.01654026\n  -0.01526608  0.00448106  0.04409116  0.05259885]] \n\n  numeric_grad\n [[ 0.00339013  0.02963675 -0.00331576  0.00066842  0.05166266  0.01660512\n  -0.01936271  0.00995913  0.01586149 -0.01602389]\n [-0.00517349 -0.02297789  0.00672213 -0.03158611 -0.01491909 -0.02681439\n   0.0074182  -0.00592797  0.00879223 -0.04433188]\n [-0.01543065  0.01599222 -0.02280474  0.02064731 -0.00284956 -0.01654026\n  -0.01526608  0.00448106  0.04409116  0.05259885]] \n\nGradient check passed!\n\nChecking gradient for fc2_B\nrun batch version of gradient check\n  analytic_grad\n [[ 0.07316861  0.11352815  0.13350763  0.07497746  0.08745139  0.10584878\n   0.10082955  0.07217977  0.11503897 -0.89125851]] \n\n  numeric_grad\n [[ 0.07316861  0.11352815  0.13350763  0.07497746  0.08745139  0.10584878\n   0.10082955  0.07217977  0.11503897 -0.89125851]] \n\nGradient check passed!\n\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.1"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 1.973762, Train accuracy: 0.230889, val accuracy: 0.252000, lr: 0.100000\n",
      "Loss: 1.751880, Train accuracy: 0.428667, val accuracy: 0.434000, lr: 0.100000\n",
      "Loss: 1.161730, Train accuracy: 0.514444, val accuracy: 0.530000, lr: 0.100000\n",
      "Loss: 1.198346, Train accuracy: 0.604667, val accuracy: 0.587000, lr: 0.100000\n",
      "Loss: 1.090121, Train accuracy: 0.671111, val accuracy: 0.651000, lr: 0.100000\n",
      "Loss: 0.471595, Train accuracy: 0.710889, val accuracy: 0.680000, lr: 0.100000\n",
      "Loss: 0.737977, Train accuracy: 0.713111, val accuracy: 0.682000, lr: 0.100000\n",
      "Loss: 0.547223, Train accuracy: 0.747222, val accuracy: 0.689000, lr: 0.100000\n",
      "Loss: 1.080923, Train accuracy: 0.738556, val accuracy: 0.706000, lr: 0.100000\n",
      "Loss: 0.420400, Train accuracy: 0.755222, val accuracy: 0.704000, lr: 0.100000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, \n",
    "                    hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-1, num_epochs=10)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1d4c6f06ba8>]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.167917, Train accuracy: 0.220778, val accuracy: 0.236000, lr: 0.099000\n",
      "Loss: 2.058752, Train accuracy: 0.398222, val accuracy: 0.393000, lr: 0.098010\n",
      "Loss: 0.976473, Train accuracy: 0.540778, val accuracy: 0.553000, lr: 0.097030\n",
      "Loss: 1.270165, Train accuracy: 0.614333, val accuracy: 0.607000, lr: 0.096060\n",
      "Loss: 1.090307, Train accuracy: 0.636667, val accuracy: 0.636000, lr: 0.095099\n",
      "Loss: 1.108789, Train accuracy: 0.673778, val accuracy: 0.644000, lr: 0.094148\n",
      "Loss: 0.785766, Train accuracy: 0.721889, val accuracy: 0.695000, lr: 0.093207\n",
      "Loss: 1.127368, Train accuracy: 0.721556, val accuracy: 0.667000, lr: 0.092274\n",
      "Loss: 0.878017, Train accuracy: 0.745556, val accuracy: 0.700000, lr: 0.091352\n",
      "Loss: 1.079874, Train accuracy: 0.765778, val accuracy: 0.693000, lr: 0.090438\n",
      "Loss: 1.293783, Train accuracy: 0.768222, val accuracy: 0.690000, lr: 0.089534\n",
      "Loss: 0.837942, Train accuracy: 0.784889, val accuracy: 0.702000, lr: 0.088638\n",
      "Loss: 0.681580, Train accuracy: 0.817444, val accuracy: 0.727000, lr: 0.087752\n",
      "Loss: 0.526593, Train accuracy: 0.815556, val accuracy: 0.727000, lr: 0.086875\n",
      "Loss: 0.368418, Train accuracy: 0.838000, val accuracy: 0.724000, lr: 0.086006\n",
      "Loss: 0.520899, Train accuracy: 0.846889, val accuracy: 0.744000, lr: 0.085146\n",
      "Loss: 0.617730, Train accuracy: 0.843778, val accuracy: 0.748000, lr: 0.084294\n",
      "Loss: 0.523522, Train accuracy: 0.838111, val accuracy: 0.720000, lr: 0.083451\n",
      "Loss: 0.494579, Train accuracy: 0.848889, val accuracy: 0.735000, lr: 0.082617\n",
      "Loss: 0.562322, Train accuracy: 0.844111, val accuracy: 0.722000, lr: 0.081791\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, \n",
    "                    reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, \n",
    "                  learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.092324, Train accuracy: 0.222556, val accuracy: 0.229000, lr: 0.099000\n",
      "Loss: 1.860824, Train accuracy: 0.379556, val accuracy: 0.389000, lr: 0.098010\n",
      "Loss: 1.590450, Train accuracy: 0.505556, val accuracy: 0.517000, lr: 0.097030\n",
      "Loss: 1.847590, Train accuracy: 0.636556, val accuracy: 0.627000, lr: 0.096060\n",
      "Loss: 1.432718, Train accuracy: 0.672444, val accuracy: 0.667000, lr: 0.095099\n",
      "Loss: 1.785398, Train accuracy: 0.718222, val accuracy: 0.693000, lr: 0.094148\n",
      "Loss: 0.947681, Train accuracy: 0.698778, val accuracy: 0.670000, lr: 0.093207\n",
      "Loss: 1.096071, Train accuracy: 0.721889, val accuracy: 0.676000, lr: 0.092274\n",
      "Loss: 0.648033, Train accuracy: 0.732556, val accuracy: 0.688000, lr: 0.091352\n",
      "Loss: 0.707297, Train accuracy: 0.747889, val accuracy: 0.704000, lr: 0.090438\n",
      "Loss: 0.667226, Train accuracy: 0.753556, val accuracy: 0.693000, lr: 0.089534\n",
      "Loss: 0.513031, Train accuracy: 0.778556, val accuracy: 0.712000, lr: 0.088638\n",
      "Loss: 0.717841, Train accuracy: 0.807667, val accuracy: 0.742000, lr: 0.087752\n",
      "Loss: 0.550896, Train accuracy: 0.799667, val accuracy: 0.721000, lr: 0.086875\n",
      "Loss: 1.029893, Train accuracy: 0.819667, val accuracy: 0.714000, lr: 0.086006\n",
      "Loss: 0.673848, Train accuracy: 0.836778, val accuracy: 0.744000, lr: 0.085146\n",
      "Loss: 0.588906, Train accuracy: 0.841222, val accuracy: 0.739000, lr: 0.084294\n",
      "Loss: 0.500806, Train accuracy: 0.822444, val accuracy: 0.724000, lr: 0.083451\n",
      "Loss: 0.589618, Train accuracy: 0.850889, val accuracy: 0.730000, lr: 0.082617\n",
      "Loss: 0.521985, Train accuracy: 0.864444, val accuracy: 0.740000, lr: 0.081791\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, \n",
    "                    reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), \n",
    "                  learning_rate=1e-1, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.343311, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.100000\nLoss: 2.319494, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.100000\n",
      "Loss: 2.344415, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.100000\nLoss: 2.301831, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.100000\nLoss: 2.282484, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.100000\nLoss: 2.227485, Train accuracy: 0.200000, val accuracy: 0.066667, lr: 0.100000\nLoss: 2.247323, Train accuracy: 0.200000, val accuracy: 0.066667, lr: 0.100000\nLoss: 2.170390, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.100000",
      "\nLoss: 2.228315, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 2.353823, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 2.006564, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000",
      "\nLoss: 2.127238, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.608926, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 2.047132, Train accuracy: 0.333333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.660990, Train accuracy: 0.333333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.851157, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\n",
      "Loss: 2.454232, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.470944, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.821988, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\n",
      "Loss: 2.178785, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.691652, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.464918, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.582852, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.925990, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.773455, Train accuracy: 0.400000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.234214, Train accuracy: 0.466667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.503882, Train accuracy: 0.466667, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.187115, Train accuracy: 0.466667, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.462689, Train accuracy: 0.466667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.942258, Train accuracy: 0.466667, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.949574, Train accuracy: 0.466667, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.643039, Train accuracy: 0.533333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.771681, Train accuracy: 0.600000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.759061, Train accuracy: 0.600000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.887799, Train accuracy: 0.600000, val accuracy: 0.066667, lr: 0.100000\nLoss: 2.179964, Train accuracy: 0.533333, val accuracy: 0.000000, lr: 0.100000\nLoss: 2.020796, Train accuracy: 0.600000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.090921, Train accuracy: 0.600000, val accuracy: 0.066667, lr: 0.100000",
      "\nLoss: 1.976898, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.449197, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.297950, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000",
      "\nLoss: 1.542805, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.171500, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.637635, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.986562, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000\nLoss: 2.052029, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.054725, Train accuracy: 0.666667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.886474, Train accuracy: 0.733333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.673229, Train accuracy: 0.733333, val accuracy: 0.133333, lr: 0.100000\nLoss: 1.156699, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.095188, Train accuracy: 0.733333, val accuracy: 0.133333, lr: 0.100000\nLoss: 1.516842, Train accuracy: 0.733333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.412652, Train accuracy: 0.733333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.458610, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.413610, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.948770, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.901573, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.355174, Train accuracy: 0.733333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.791769, Train accuracy: 0.733333, val accuracy: 0.133333, lr: 0.100000",
      "\nLoss: 1.922676, Train accuracy: 0.733333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.656876, Train accuracy: 0.733333, val accuracy: 0.066667, lr: 0.100000\nLoss: 2.095059, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.693867, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000",
      "\nLoss: 1.658368, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.710144, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.984833, Train accuracy: 0.800000, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.694758, Train accuracy: 0.866667, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.278300, Train accuracy: 0.866667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.340980, Train accuracy: 0.866667, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.254693, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.557730, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.522803, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.661825, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000",
      "\nLoss: 1.678061, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.649513, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.442781, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.419692, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.280261, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.280827, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.508549, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.251723, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.367962, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.264583, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.827399, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.194376, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.517925, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.251765, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.546441, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.505875, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.310843, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.310200, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.470709, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\n",
      "Loss: 1.498062, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.170556, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.175903, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.277560, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000",
      "\nLoss: 1.305250, Train accuracy: 0.933333, val accuracy: 0.066667, lr: 0.100000\nLoss: 1.349195, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.284261, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.142537, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.118618, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\n",
      "Loss: 1.613488, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.283754, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.600273, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\n",
      "Loss: 1.222109, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.247810, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.274772, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.164365, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.269793, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.266279, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.492541, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000",
      "\nLoss: 1.278787, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.118925, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\n",
      "Loss: 1.292824, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.234724, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.159691, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.581165, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.222135, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.334998, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000",
      "\nLoss: 1.272473, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.584695, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.188293, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\n",
      "Loss: 1.286153, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.379700, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.176025, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.190443, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.336935, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.170954, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.617802, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000",
      "\nLoss: 1.278333, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.366067, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.352405, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000",
      "\nLoss: 1.500938, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.290282, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.180586, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.290144, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.102963, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.101868, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\n",
      "Loss: 1.152287, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.415761, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.287221, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.455727, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.357959, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.042405, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.305173, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.375391, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000",
      "\nLoss: 1.316192, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.349455, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.448131, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\nLoss: 1.341960, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.100000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, \n",
    "                    reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.339336, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.300000\nLoss: 2.278314, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.300000\nLoss: 2.266186, Train accuracy: 0.200000, val accuracy: 0.133333, lr: 0.300000\nLoss: 2.322997, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.300000\nLoss: 2.072852, Train accuracy: 0.333333, val accuracy: 0.000000, lr: 0.300000\n",
      "Loss: 2.331758, Train accuracy: 0.333333, val accuracy: 0.066667, lr: 0.300000\nLoss: 1.979863, Train accuracy: 0.466667, val accuracy: 0.133333, lr: 0.300000\nLoss: 1.609449, Train accuracy: 0.466667, val accuracy: 0.000000, lr: 0.300000\nLoss: 1.739748, Train accuracy: 0.400000, val accuracy: 0.000000, lr: 0.300000\nLoss: 1.246179, Train accuracy: 0.400000, val accuracy: 0.066667, lr: 0.300000\nLoss: 1.246652, Train accuracy: 0.466667, val accuracy: 0.000000, lr: 0.300000\n",
      "Loss: 1.905688, Train accuracy: 0.466667, val accuracy: 0.066667, lr: 0.300000\nLoss: 1.475181, Train accuracy: 0.666667, val accuracy: 0.000000, lr: 0.300000\nLoss: 1.327172, Train accuracy: 0.600000, val accuracy: 0.066667, lr: 0.300000\n",
      "Loss: 1.270285, Train accuracy: 0.733333, val accuracy: 0.000000, lr: 0.300000\nLoss: 0.731440, Train accuracy: 0.866667, val accuracy: 0.000000, lr: 0.300000\nLoss: 0.624501, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.300000\nLoss: 0.473138, Train accuracy: 0.933333, val accuracy: 0.000000, lr: 0.300000\nLoss: 0.040159, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.300000\nLoss: 0.241249, Train accuracy: 1.000000, val accuracy: 0.000000, lr: 0.300000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, \n",
    "                    reg = 0)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=3e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.335491, Train accuracy: 0.228556, val accuracy: 0.241000, lr: 0.099000\n",
      "Loss: 1.208105, Train accuracy: 0.437667, val accuracy: 0.427000, lr: 0.098010\n",
      "Loss: 1.438915, Train accuracy: 0.545889, val accuracy: 0.541000, lr: 0.097030\n",
      "Loss: 1.687071, Train accuracy: 0.544333, val accuracy: 0.545000, lr: 0.096060\n",
      "Loss: 1.045004, Train accuracy: 0.688778, val accuracy: 0.669000, lr: 0.095099\n",
      "Loss: 1.007206, Train accuracy: 0.694778, val accuracy: 0.653000, lr: 0.094148\n",
      "Loss: 1.329185, Train accuracy: 0.730444, val accuracy: 0.684000, lr: 0.093207\n",
      "Loss: 1.178206, Train accuracy: 0.723667, val accuracy: 0.681000, lr: 0.092274\n",
      "Loss: 1.055999, Train accuracy: 0.756556, val accuracy: 0.709000, lr: 0.091352\n",
      "Loss: 0.294374, Train accuracy: 0.771000, val accuracy: 0.719000, lr: 0.090438\n",
      "Loss: 0.623206, Train accuracy: 0.784111, val accuracy: 0.718000, lr: 0.089534\n",
      "Loss: 0.397552, Train accuracy: 0.801778, val accuracy: 0.723000, lr: 0.088638\n",
      "Loss: 0.889256, Train accuracy: 0.803444, val accuracy: 0.729000, lr: 0.087752\n",
      "Loss: 0.449847, Train accuracy: 0.830778, val accuracy: 0.723000, lr: 0.086875\n",
      "Loss: 0.817772, Train accuracy: 0.845778, val accuracy: 0.731000, lr: 0.086006\n",
      "Loss: 1.001910, Train accuracy: 0.818778, val accuracy: 0.717000, lr: 0.085146\n",
      "Loss: 0.696652, Train accuracy: 0.852444, val accuracy: 0.753000, lr: 0.084294\n",
      "Loss: 0.213679, Train accuracy: 0.847111, val accuracy: 0.734000, lr: 0.083451\n",
      "Loss: 0.500673, Train accuracy: 0.869000, val accuracy: 0.752000, lr: 0.082617\n",
      "Loss: 0.339744, Train accuracy: 0.877444, val accuracy: 0.756000, lr: 0.081791\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-1\n",
    "reg_strength = 1e-5\n",
    "learning_rate_decay = 0.99\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 20\n",
    "batch_size = 20\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, \n",
    "                    hidden_layer_size = hidden_layer_size, reg = reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), \n",
    "                  learning_rate=learning_rates, learning_rate_decay=learning_rate_decay, \n",
    "                  num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of validation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "# print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "best_classifier = model\n",
    "best_val_accuracy = 0.756"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1d4d9549fd0>]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 54
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x504 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Neural net test set accuracy: 0.723000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}